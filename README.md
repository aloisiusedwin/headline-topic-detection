ğŸ“° Identifikasi Topik Berita Berdasarkan Judul
Menggunakan Word Embedding (Word2Vec) dan Long Short-Term Memory (LSTM)

Repository ini berisi implementasi lengkap sistem klasifikasi topik berita berdasarkan judul berita dengan memanfaatkan Word Embedding berbasis Word2Vec Wikipedia Indonesia dan model LSTM/GRU. Pipeline dibangun modular melalui beberapa notebook terpisah yang mencakup proses dari pengecekan dataset hingga inference akhir.

ğŸ“Œ Fitur Utama

Word Embedding hasil pelatihan Word2Vec Wikipedia Indonesia

Integrasi embedding matrix ke model PyTorch

Arsitektur LSTM dan GRU

Stratified K-Fold Cross Validation

Penanganan imbalance dataset (undersampling)

Pipeline modular: database â†’ preprocess â†’ embedding â†’ training â†’ inference

Pemilihan model terbaik otomatis (LSTM atau GRU)

ğŸ—‚ï¸ Struktur Repository
headline-topic-detection/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ indonesian-news-title.csv
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ vocab/                # word2idx.pkl
â”‚   â”œâ”€â”€ labels/               # label encoder
â”‚   â”œâ”€â”€ embedding/            # embedding matrix, dump wiki, extract text
â”‚   â”œâ”€â”€ config/               # konfigurasi model akhir
â”‚   â””â”€â”€ model_final/          # model terbaik
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ idwiki_word2vec.model (+ .npy)
â”‚
â”œâ”€â”€ database.ipynb            # pengecekan dataset + undersampling
â”œâ”€â”€ preprocess.ipynb          # preprocessing & encoding token
â”œâ”€â”€ embedding.ipynb           # membuat embedding matrix
â”œâ”€â”€ training.ipynb            # training LSTM & GRU + K-Fold
â”œâ”€â”€ inference.ipynb           # prediksi headline baru
â”œâ”€â”€ train_embedding.py        # pelatihan Word2Vec Wikipedia
â””â”€â”€ README.md
âš™ï¸ Instalasi

Gunakan Python 3.10 / 3.11.

pip install -r requirements.txt

Jika muncul error NumPy 2.x:

pip install "numpy<2"
â–¶ï¸ Pipeline Pengolahan
1. database.ipynb â€” Pengecekan Data & Undersampling

Menampilkan distribusi kelas

Menyeimbangkan dataset (undersampling)

Menyimpan dataset final

2. preprocess.ipynb â€” Preprocessing & Encoding

Normalisasi teks (lowercase, regex)

Tokenisasi

Pembuatan vocabulary (word2idx)

Padding

Encoding label

Output utama:

word2idx.pkl

label_encoder.pkl

X.npy, y.npy

3. embedding.ipynb â€” Word2Vec Integration

Memuat Word2Vec Wikipedia

Membangun embedding matrix berdasarkan vocabulary

Menyimpan embedding_matrix.npy

4. training.ipynb â€” Training Model

Arsitektur LSTM dan GRU

Stratified K-Fold

Fine-tuning embedding

Penyimpanan model terbaik

Output:

final_model.pth

config.json (berisi jenis model terbaik: lstm/gru)

5. inference.ipynb â€” Prediksi Headline Baru

Memuat config

Memilih model terbaik (otomatis)

Encoding teks â†’ prediksi kategori

ğŸ§ª Contoh Inputâ€“Output

Input:

"Putri KW Enggan Terbebani SEA Games dan World Tour Finals"

Output:

sport
ğŸ—ï¸ Arsitektur Model
Input â†’ Word2Vec Embedding â†’ LSTM/GRU â†’ Dense â†’ Softmax
ğŸ“Š Evaluasi Model

Menggunakan Stratified K-Fold untuk menjaga distribusi label tiap fold.

Metrik:

Accuracy

Precision (weighted)

Recall (weighted)

F1-score (weighted)

Model terbaik dipilih berdasarkan rata-rata F1-score.

ğŸ“ Rencana Pengembangan

Penambahan data augmentation (EDA / synonym replacement / back-translation)

Pembandingan berbagai skema embedding (random vs Word2Vec)

Ekspor model ke ONNX (?)
