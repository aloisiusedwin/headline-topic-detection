{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd81b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c159f68",
   "metadata": {},
   "source": [
    "- Pada bagian ini, dataset hasil preprocessing (X dan y) akan dibagi menjadi beberapa fold menggunakan K-Fold.  \n",
    "- Setiap fold akan dilatih dan dievaluasi menggunakan LSTM dan GRU.  \n",
    "- Tujuannya: memperoleh performa rata-rata yang stabil dan memilih model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"dataset\", \"indonesian-news-title.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fd25a",
   "metadata": {},
   "source": [
    "### Step 1 — Load artefak preprocessing\n",
    "Kita ambil vocab, label encoder, config, dan dataset encoded yang dibuat di fase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2a33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocab, label encoder, config\n",
    "with open(\"artifacts/vocab/word2idx.pkl\", \"rb\") as f:\n",
    "    word2idx = pickle.load(f)\n",
    "\n",
    "with open(\"artifacts/labels/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"artifacts/config/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "MAX_LEN = config[\"max_len\"]\n",
    "VOCAB_SIZE = config[\"vocab_size\"]\n",
    "NUM_CLASSES = config[\"num_classes\"]\n",
    "EMBED_DIM = config[\"embedding_dim\"]\n",
    "HIDDEN_SIZE = config[\"hidden_size\"]\n",
    "\n",
    "# Load balanced & encoded dataset\n",
    "X = np.load(\"artifacts/dataset/X.npy\")\n",
    "y = np.load(\"artifacts/dataset/y.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421fcfc",
   "metadata": {},
   "source": [
    "### Step 2 — Siapkan Dataset dan DataLoader\n",
    "Dataset ini dipake PyTorch buat ngasih data dalam bentuk batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = NewsDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539ea81",
   "metadata": {},
   "source": [
    "### Step 3 — Bikin arsitektur model LSTM dan GRU\n",
    "Kedua model ini mirip, cuma beda di jenis recurrent layer-nya.  \n",
    "Tambahin Word Embedding juga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6013c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"artifacts/embedding/embedding_matrix.npy\")\n",
    "EMBED_DIM = embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2150ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32),\n",
    "            freeze=False   # kalau mau fine-tuning, True kalau mau tetap\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(h[-1])\n",
    "\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32),\n",
    "            freeze=False   # kalau mau fine-tuning, True kalau mau tetap\n",
    "        )\n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bc786",
   "metadata": {},
   "source": [
    "### Step 4 — Setup K-Fold untuk bagi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903be5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee62462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17539 4385\n",
      "17539 4385\n",
      "17539 4385\n",
      "17539 4385\n",
      "17540 4384\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    print(len(train_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3f56e",
   "metadata": {},
   "source": [
    "### Step 5 — Loop K-Fold Training + Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c890b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = clean_text(text).split()\n",
    "    seq = [word2idx.get(tok, word2idx[\"<UNK>\"]) for tok in tokens]\n",
    "\n",
    "    if len(seq) < MAX_LEN:\n",
    "        seq = seq + [word2idx[\"<PAD>\"]] * (MAX_LEN - len(seq))\n",
    "    else:\n",
    "        seq = seq[:MAX_LEN]\n",
    "\n",
    "    return torch.tensor([seq], dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad71b7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7456, -0.1253, -1.0992,  0.1143,  0.0916,  0.1585, -0.1856, -0.0210,\n",
      "         0.5227, -0.2509], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 20, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = LSTMClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "print(lstm_model.emb.weight[10][:10])\n",
    "\n",
    "test = encode_text(\"jokowi resmikan proyek tol baru\")\n",
    "\n",
    "# pastikan list int\n",
    "if isinstance(test, torch.Tensor):\n",
    "    test = test.tolist()\n",
    "\n",
    "inp = torch.tensor([test], dtype=torch.long).to(device)\n",
    "\n",
    "vecs = lstm_model.emb(inp).shape\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a350f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1 =====\n",
      "LSTM fold 1: (0.809806157354618, 0.8129945646324171, 0.809806157354618, 0.8097650282788484)\n",
      "GRU  fold 1: (0.8102622576966932, 0.8111068985416936, 0.8102622576966932, 0.8101215034083125)\n",
      "\n",
      "===== FOLD 2 =====\n",
      "LSTM fold 2: (0.8189281641961231, 0.8227149492533088, 0.8189281641961231, 0.8187607476643184)\n",
      "GRU  fold 2: (0.8088939566704675, 0.8135529814737781, 0.8088939566704675, 0.810075701514098)\n",
      "\n",
      "===== FOLD 3 =====\n",
      "LSTM fold 3: (0.8326111744583808, 0.8337795208723884, 0.8326111744583808, 0.8326548798458193)\n",
      "GRU  fold 3: (0.8198403648802737, 0.8233190972701442, 0.8198403648802737, 0.8198339482165907)\n",
      "\n",
      "===== FOLD 4 =====\n",
      "LSTM fold 4: (0.8084378563283923, 0.8119052386901777, 0.8084378563283923, 0.8085174090956248)\n",
      "GRU  fold 4: (0.8136830102622576, 0.8156997209369249, 0.8136830102622576, 0.8134235515701538)\n",
      "\n",
      "===== FOLD 5 =====\n",
      "LSTM fold 5: (0.8186587591240876, 0.8218755345368186, 0.8186587591240876, 0.8184989922793983)\n",
      "GRU  fold 5: (0.8204835766423357, 0.8234414446843314, 0.8204835766423357, 0.8210897335575352)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "lstm_scores = []\n",
    "gru_scores = []\n",
    "fold_no = 1\n",
    "\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    print(f\"\\n===== FOLD {fold_no} =====\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Dataset & Loader\n",
    "    train_loader = DataLoader(\n",
    "        NewsDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        NewsDataset(X_test, y_test), batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Init models\n",
    "    lstm_model = LSTMClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "    gru_model  = GRUClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lstm_opt = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "    gru_opt  = torch.optim.Adam(gru_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # === TRAIN LSTM ===\n",
    "    for epoch in range(EPOCHS):\n",
    "        lstm_model.train()\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            lstm_opt.zero_grad()\n",
    "            out = lstm_model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            lstm_opt.step()\n",
    "\n",
    "    # === TRAIN GRU ===\n",
    "    for epoch in range(EPOCHS):\n",
    "        gru_model.train()\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            gru_opt.zero_grad()\n",
    "            out = gru_model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            gru_opt.step()\n",
    "\n",
    "    # === EVALUASI ===\n",
    "    def evaluate(model):\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                out = model(Xb)\n",
    "                pred = torch.argmax(out, dim=1).cpu().tolist()\n",
    "                true.extend(yb.tolist())\n",
    "                preds.extend(pred)\n",
    "\n",
    "        acc = accuracy_score(true, preds)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            true, preds, average=\"weighted\"\n",
    "        )\n",
    "\n",
    "        return acc, prec, rec, f1\n",
    "\n",
    "    # simpan skor\n",
    "    lstm_scores.append(evaluate(lstm_model))\n",
    "    gru_scores.append(evaluate(gru_model))\n",
    "\n",
    "    print(f\"LSTM fold {fold_no}:\", lstm_scores[-1])\n",
    "    print(f\"GRU  fold {fold_no}:\", gru_scores[-1])\n",
    "\n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74fcee6",
   "metadata": {},
   "source": [
    "### Step 6 — Rata-rata skor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd58d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Rata-rata Hasil K-Fold =====\n",
      "LSTM (acc, prec, rec, f1): [0.81768842 0.82065396 0.81768842 0.81763941]\n",
      "GRU  (acc, prec, rec, f1): [0.81463263 0.81742403 0.81463263 0.81490889]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n===== Rata-rata Hasil K-Fold =====\")\n",
    "\n",
    "lstm_mean = np.mean(lstm_scores, axis=0)\n",
    "gru_mean  = np.mean(gru_scores, axis=0)\n",
    "\n",
    "print(\"LSTM (acc, prec, rec, f1):\", lstm_mean)\n",
    "print(\"GRU  (acc, prec, rec, f1):\", gru_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbdd534",
   "metadata": {},
   "source": [
    "### Step 7 — Simpan model terlatih (F1 tertinggi)\n",
    "Biar nanti bisa dipakai di fase inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21cefd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: lstm\n"
     ]
    }
   ],
   "source": [
    "best_model_name = \"lstm\" if lstm_mean[3] > gru_mean[3] else \"gru\"\n",
    "config[\"best_model_type\"] = best_model_name\n",
    "\n",
    "with open(\"artifacts/config/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "os.makedirs(\"artifacts/model_final\", exist_ok=True)\n",
    "\n",
    "if best_model_name == \"lstm\":\n",
    "    torch.save(lstm_model.state_dict(), \"artifacts/model_final/final_model.pth\")\n",
    "else:\n",
    "    torch.save(gru_model.state_dict(), \"artifacts/model_final/final_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "headline-topic-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
