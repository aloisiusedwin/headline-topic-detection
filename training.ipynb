{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd81b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c159f68",
   "metadata": {},
   "source": [
    "- Pada bagian ini, dataset hasil preprocessing (X dan y) akan dibagi menjadi beberapa fold menggunakan K-Fold.  \n",
    "- Setiap fold akan dilatih dan dievaluasi menggunakan LSTM dan GRU.  \n",
    "- Tujuannya: memperoleh performa rata-rata yang stabil dan memilih model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"dataset\", \"indonesian-news-title.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fd25a",
   "metadata": {},
   "source": [
    "### Step 1 — Load artefak preprocessing\n",
    "Kita ambil vocab, label encoder, config, dan dataset encoded yang dibuat di fase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2a33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocab, label encoder, config\n",
    "with open(\"artifacts/vocab/word2idx.pkl\", \"rb\") as f:\n",
    "    word2idx = pickle.load(f)\n",
    "\n",
    "with open(\"artifacts/labels/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"artifacts/config/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "MAX_LEN = config[\"max_len\"]\n",
    "VOCAB_SIZE = config[\"vocab_size\"]\n",
    "NUM_CLASSES = config[\"num_classes\"]\n",
    "EMBED_DIM = config[\"embedding_dim\"]\n",
    "HIDDEN_SIZE = config[\"hidden_size\"]\n",
    "\n",
    "# Load balanced & encoded dataset\n",
    "X = np.load(\"artifacts/dataset/X.npy\")\n",
    "y = np.load(\"artifacts/dataset/y.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421fcfc",
   "metadata": {},
   "source": [
    "### Step 2 — Siapkan Dataset dan DataLoader\n",
    "Dataset ini dipake PyTorch buat ngasih data dalam bentuk batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = NewsDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539ea81",
   "metadata": {},
   "source": [
    "### Step 3 — Bikin arsitektur model LSTM dan GRU\n",
    "Kedua model ini mirip, cuma beda di jenis recurrent layer-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2150ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(h[-1])\n",
    "\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bc786",
   "metadata": {},
   "source": [
    "### Step 4 — Setup K-Fold untuk bagi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903be5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee62462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17539 4385\n",
      "17539 4385\n",
      "17539 4385\n",
      "17539 4385\n",
      "17540 4384\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    print(len(train_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3f56e",
   "metadata": {},
   "source": [
    "### Step 5 — Loop K-Fold Training + Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a350f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1 =====\n",
      "LSTM fold 1: (0.7074116305587229, 0.7125586937186793, 0.7074116305587229, 0.7076944044132734)\n",
      "GRU  fold 1: (0.7131128848346636, 0.7212991453486725, 0.7131128848346636, 0.7139403622822386)\n",
      "\n",
      "===== FOLD 2 =====\n",
      "LSTM fold 2: (0.6919042189281642, 0.6947329845770048, 0.6919042189281642, 0.6909226516534106)\n",
      "GRU  fold 2: (0.70672748004561, 0.7125030334177592, 0.70672748004561, 0.7077259839824257)\n",
      "\n",
      "===== FOLD 3 =====\n",
      "LSTM fold 3: (0.7179019384264538, 0.7232106265737465, 0.7179019384264538, 0.7195276759155843)\n",
      "GRU  fold 3: (0.732497149372862, 0.7382582737979372, 0.732497149372862, 0.7335533055378547)\n",
      "\n",
      "===== FOLD 4 =====\n",
      "LSTM fold 4: (0.7005701254275941, 0.7025844577439528, 0.7005701254275941, 0.7009818832354554)\n",
      "GRU  fold 4: (0.720866590649943, 0.7226886664663911, 0.720866590649943, 0.7213545436544628)\n",
      "\n",
      "===== FOLD 5 =====\n",
      "LSTM fold 5: (0.698220802919708, 0.7083391326444863, 0.698220802919708, 0.7002311126300002)\n",
      "GRU  fold 5: (0.7052919708029197, 0.7063151106428104, 0.7052919708029197, 0.7048120817774705)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "lstm_scores = []\n",
    "gru_scores = []\n",
    "fold_no = 1\n",
    "\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    print(f\"\\n===== FOLD {fold_no} =====\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Dataset & Loader\n",
    "    train_loader = DataLoader(\n",
    "        NewsDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        NewsDataset(X_test, y_test), batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Init models\n",
    "    lstm_model = LSTMClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "    gru_model  = GRUClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lstm_opt = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "    gru_opt  = torch.optim.Adam(gru_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # === TRAIN LSTM ===\n",
    "    for epoch in range(EPOCHS):\n",
    "        lstm_model.train()\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            lstm_opt.zero_grad()\n",
    "            out = lstm_model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            lstm_opt.step()\n",
    "\n",
    "    # === TRAIN GRU ===\n",
    "    for epoch in range(EPOCHS):\n",
    "        gru_model.train()\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            gru_opt.zero_grad()\n",
    "            out = gru_model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            gru_opt.step()\n",
    "\n",
    "    # === EVALUASI ===\n",
    "    def evaluate(model):\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                out = model(Xb)\n",
    "                pred = torch.argmax(out, dim=1).cpu().tolist()\n",
    "                true.extend(yb.tolist())\n",
    "                preds.extend(pred)\n",
    "\n",
    "        acc = accuracy_score(true, preds)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            true, preds, average=\"weighted\"\n",
    "        )\n",
    "\n",
    "        return acc, prec, rec, f1\n",
    "\n",
    "    # simpan skor\n",
    "    lstm_scores.append(evaluate(lstm_model))\n",
    "    gru_scores.append(evaluate(gru_model))\n",
    "\n",
    "    print(f\"LSTM fold {fold_no}:\", lstm_scores[-1])\n",
    "    print(f\"GRU  fold {fold_no}:\", gru_scores[-1])\n",
    "\n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74fcee6",
   "metadata": {},
   "source": [
    "### Step 6 — Rata-rata skor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd58d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Rata-rata Hasil K-Fold =====\n",
      "LSTM (acc, prec, rec, f1): [0.70320174 0.70828518 0.70320174 0.70387155]\n",
      "GRU  (acc, prec, rec, f1): [0.71569922 0.72021285 0.71569922 0.71627726]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n===== Rata-rata Hasil K-Fold =====\")\n",
    "\n",
    "lstm_mean = np.mean(lstm_scores, axis=0)\n",
    "gru_mean  = np.mean(gru_scores, axis=0)\n",
    "\n",
    "print(\"LSTM (acc, prec, rec, f1):\", lstm_mean)\n",
    "print(\"GRU  (acc, prec, rec, f1):\", gru_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbdd534",
   "metadata": {},
   "source": [
    "### Step 7 — Simpan model terlatih (F1 tertinggi)\n",
    "Biar nanti bisa dipakai di fase inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21cefd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: gru\n"
     ]
    }
   ],
   "source": [
    "best_model_name = \"lstm\" if lstm_mean[3] > gru_mean[3] else \"gru\"\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "os.makedirs(\"artifacts/model_final\", exist_ok=True)\n",
    "\n",
    "if best_model_name == \"lstm\":\n",
    "    torch.save(lstm_model.state_dict(), \"artifacts/model_final/final_model.pth\")\n",
    "else:\n",
    "    torch.save(gru_model.state_dict(), \"artifacts/model_final/final_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "headline-topic-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
